> 这周的学习感觉比较宽泛，主要还是先寻找一下选题和确定一下大方向之类的。

# 本周主要工作：

1. 乳腺癌检测识别的kaggle实战，
2. 乳腺癌识别检测的1篇论文
3. 半监督医学图像分割论文的十篇论文笔记，
4. 类不均衡的笔记，
5. 强化学习学习的概要笔记，
6. 迁移学习的介绍笔记，
7. 课程学习的综述论文，
8. 课程学习的高引论文四篇以及笔记。
9. 其他

# 简要回顾总结：

## 1.乳腺癌检测识别的kaggle实战

代码地址：

```tcl
/DeepLearning_StudyNote/Semi_Supervised_Learning_Medical_Image_Segmentation/Breast_Cancer_Iecognition/Kaggle_BCI_3C_Code
```

首先是获取数据集之后对其进行裁剪，得到的放在输出之中，然后在输出的位置读取作为输入进行数据增强，然后划分数据集。然后导入resnet50和官方权重，这个算是模板代码这一段，然后是训练的代码，使用了早停法，然后是评估函数。整个代码通过7-8次的迭代就可以达到96%的准确率。这里让我了解到的就是不一定非得用分割，直接使用resnet50和官方权重不仅省时间还节省了代码的长度，而且精度也还不错。

## 2.乳腺癌识别检测的1篇论文

当时是想往半监督医学图像分割去做的，而且比赛的题目也是这个，所以当时想看这些论文，但是这里好多论文其实太久远了，也没有怎么看，只选了几篇阅读。

```tcl
/DeepLearning_StudyNote/Semi_Supervised_Learning_Medical_Image_Segmentation/Breast_Cancer_Iecognition/Breast_Cancer_Diagnosis_Paper/Note/Learn_Note.md
```

An interpretable classifier for high-resolution breast cancer screening images utilizing weakly supervised localization 利用弱监督定位的高分辨率乳腺癌筛查图像的可解释分类器

![网络架构图片](./Images/mia_structure.png)



整体的感受就是这个代码的逻辑非常清楚是我喜欢的风格。前面是定义函数，后面是主函数以及参数的设置，最后所有的执行操作都通过shell进行，非常nice！然后就是整个网络的架构图，能把这一张图片看懂，整个论文也就算学到一点知识了。

总结一下这篇论文就是，通过把输入图像进行预处理，采用裁剪的手法，然后再提取乳腺图像的最佳中心点，记录处理后的图片以及保存地址列表。最后输送到模型中进行学习。

整体的模型有全局模型，局部模型和融合模型，同样对应着三个BCE损失函数。在全局模型中，首先对输入的图像进行低容量全局网络处理可以得到图片的显著特征图片，然后可以和人工标注的图片做一个BCE；这个特征图片经过ROI得到补丁后的图片，把补丁后的图片和原始图片融合裁剪之后就是ROI图片，对这个图片进行高容量局部网络模型，得到特征向量之后做一个attention得到注意力权重表示然后将全局模型中得到的卷积层做一个池化操作两者相拼接，送给sigmoid与标注的图片对比得到一个BCE。最终的损失就由这三者的加权得到，不断改进更新模型。

## 3.半监督医学图像分割论文的十篇论文笔记

```tcl
/DeepLearning_StudyNote/Semi_Supervised_Learning_Medical_Image_Segmentation/SSL4MIS_ListNote/SSL_MIS_Note.md 
```

这里是我按照半监督医学图像分割的合集论文从最上面往下看的10篇文章。

首先第一篇讲的是类不均衡，也是基于此我往后面学习了类不均衡的概念，使用欠采样，过采样，调整权重等方法主流。论文是使用了双除偏异构协同训练框架。具体我也没看到，这篇的收获就是知道了类不均衡这个概念以及后续我也需要考虑这个问题。

然后是使用元过程动态分配权重为伪标签增强PLE，在干净的数据集上自我引导。有点像课程学习那回事了。然后是多视角不确定性引导，使用对抗学习的双视角协同框架对每一个视图的高置信预测中学习到有用的知识，确保两个视图都可以有靠谱的预测，两个网络取长补短。

然后是一个新的相关感知相互学习框架，利用标记数据指导未标记数据提取信。歧义选择性一致性正则化，半监督医学图像分割的上下文感知条件交叉伪监督，自感知和跨样本原型学习方法，正交注释有利于无监督的医学图像分割，伪标签引导对比学习。

总的来说这些论文的核心思想就是在伪标签上做文章，让伪标签变强可以使用相互感知，标签引导，歧义选择，上下文感知交叉对比，自感知跨样本，伪标签引导对比学习。这些都是。

然后有的是多视角：正交注释，多视角不确定性引导。

然后是单出来的类不均衡，元过程动态分配权重为伪标签增强PLE(这个真的有点课程学习的味道)

所以可以分成四类文章：伪标签，多视角，类不均衡，课程学习。

## 4.类不均衡的笔记

```tcl
/DeepLearning_StudyNote/Class_Imbalance/Class_Imbalance_Note.md 
```

wok我这周学了这么多的吗，现在十一点了得回宿舍了，明天再写算了。

采用半监督进行医学图像分割，为什么效果没有很大提升？https://www.zhihu.com/question/537654720/answer/3084586769

> 这篇文章写得非常好，提到了图像分割中样本的不平衡有前景背景像素之间的，有简单困难之间的。常见的解决办法在数据级和算法级，前者欠采样和过采样，后者改进损失函数，加权或者换指标。

其实类不均衡天然地和课程学习相结合，内在逻辑核心思想层面是相通的。

[干货总结] 常见的类别不平衡问题解决方法https://zhuanlan.zhihu.com/p/556158050

> ADASYN：adaptive synthetic sampling 也是SMOTE的一种改进方法。
>
> 基本思想是根据学习难度的不同，对不同的少数类别的样本使用加权分布，比较容易学习的少数类样本，对于难以学习的少数类的样本，产生更多的综合数据。 因此，ADASYN方法通过两种方式改善了对数据分布的学习：（1）减少类不平衡引入的偏差，（2）将分类决策边界自适应地转移到困难的样本。
>
> 具体实现算法介绍
>
> https://zhuanlan.zhihu.com/p/94599093

## 5.强化学习学习的概要笔记

强化学习是属于机器学习的一种方法，通过与环境进行交互来学习到最佳的策略。也就是一个智能体执行相应的动作与外界交互后得到的状态及奖励判断出最佳的策略，实现长期奖励的最大化。

和研究的领域相关的自然是深度强化学习，其实就是深度学习和强化学习相结合并没有什么其他的。

以图像分割来说，这个智能体就是模型，环境的交互就是这个损失函数，得到的奖励可以写一个函数判定，状态由自己定义的评估指标确定，然后不断的学习到分割的边界，达到最优的策略，就是这样喵～ 

近期研究热点

1. **自动化课程学习（Automated Curriculum Learning）**：动态调整学习任务的难度，提升学习效率和效果。
2. **元强化学习（Meta-Reinforcement Learning）**：学习如何学习，提升在新任务上的快速适应能力。

这两个方向像ACL就是目前学习的地方，所以强化学习也需要看相关的论文，元强化学习是一个比较高级的方法吧，至少名字听起来就不错

## 6.迁移学习的介绍笔记

迁移学习也和课程学习相关所以先了解了一部分，总共有四种迁移：实例，特征，参数，结构。我想到meanteacher的EMA其实就是参数迁移，将学生参数和前一个老师参数迁移到新的，虽然有点牵强，但可以这么理解。

## 7.课程学习的综述论文

> 本来是写了一个计划的在CL_README.md。但是师兄说学术是没有计划的，好像对着的。创新点改实验这个是不可估计的，可以估计的是每天看多少论文，50篇论文什么时候看完这个是需要计划的，计划就是每天看一篇到两篇，然后记得写笔记，每天写一个日记，每周写一个每周学术总结，不开源的话就会拖，所以就开源写。

课程学习的核心思想就是像人类一样学习，从易到难给简单的分配多一些的权重，为难以训练的样本给予更大的惩罚，分配较小的权重，让模型逐步提升泛化能力。

实现思路主要有七类：普通课程学习（CL），自步学习（SPL），平衡课程学习（BCL），自步课程学习（SPCL），教师课程学习（TSCL），渐进式学习（PCL），隐式学习（ICL）。然后现在的话CL和SPL基本也不会使用了，因为有SPCL比较好，然后考虑到类不均衡在图像分割中的一大挑战，BCL应该也要重点学习，整体的框架肯定是需要TSCL的，这个半监督框架是重点学习的，剩下的就是PCL，ICL这两个的话我看一下，能把其中的思想学到就行。然后是ACL是一个重点和元学习也是，这两个属于强化学习也是重点，再就是迁移学习需要一起学。哎要学的好多啊。还有期末考试呢。

综述最后在四个方面提出了一个可研究的方向：寻找课程学习的误区，模型和性能层面并未很好的探索，在无监督和自监督领域的应用，SGD算法的改进。像我们的思路就是寻找半监督领域中课程学习的误区，通过改进SGD算法和Loss函数和性能评价指标，模型就不考虑了，直接用resnet50和101我想的是提出一个框架，不注重模型的选择了。

## 8.课程学习的高引论文四篇以及笔记

这四篇论文分别讲了TSCL，ACL，SPCL，和课程学习在训练深度学习的作用。你想就是前三篇都是理论基础的文章，注重公式理论算法的设计，第四篇就是进行了实验结论是课程学习很nice。其中SPCL也介绍和对比了CL，SPL，因为是结合两者的优缺点。

- TSCL的***核心思想是让学生模型学习进度最快的任务就是曲线斜率最高，为防止遗忘，学生还应该练习表现越差的任务就是曲线斜率为负的时候***。（实现的话比如meanteacher）

- ACL的***核心思想是一种通过动态调整训练实例难度来增强神经网络训练的技术。使课程适应网络的学习速度和提升泛化能力，优化网络提升性能。***（*在实现ACL的方法上，可以使用网络性能来确定示例的难度，或者使用强化学习来优化课程本身*。）

- SPCL的***核心思想是提出的框架解决了CL受限于先验知识，SPL受限于自步函数，结合两者形成的SPCL即可用先验知识还可以动态调整自步函数，泛化模型。***

- 课程学习很nice～

## 9.其他

总结其实挺好的，写一个总结的时候知道这一周做了哪些工作，然后有哪些地方其实都忘了，哪些地方好像没有那么重要，有些地方再看一个有不一样的理解，因为学到的知识变多了，再去看先前的知识的时候就会联系到现在学的知识和问题。我觉得课程学习也应该写一个总结的功能，别老自己在那读输入然后自己调整参数，复习然后调整，丝丝，这个还想多训练就是复习吧，毕竟题库都给了，只有这么多数据，下次再想，多看点论文，这个估计也有文章了，现在看得文章还不够，这些高引用量的都是理论思想类的，看完了之后就是模型构建类的，看别人是怎么结合这些思想实现的。每天至少一篇论文就ok，不要想着发论文，不要急，发不出来又怎么样，就当兴趣爱好罢了。

-2024.05.27

本来是昨天写完的，太晚了得回宿舍了，所以星期一才写完后面的内容



